= OpenVino Driver Behaviour
:idprefix:
:idseparator: -
:sectanchors:
:sectlinks:
:sectnumlevels: 6
:sectnums:
:toc: macro
:toclevels: 6
:toc-title: Table of Contents

https://travis-ci.org/incluit/OpenVino-Driver-Behaviour#[image:https://travis-ci.org/incluit/OpenVino-Driver-Behaviour.svg?branch=master[Build
Status]]
https://sonarcloud.io/dashboard?id=incluit_OpenVino-Driver-Behaviour[image:https://sonarcloud.io/api/project_badges/measure?project=incluit_OpenVino-Driver-Behaviour&metric=alert_status[Sonarcloud
Status]]

toc::[]

== Foreword
This is a follow-up on the OpenVino's inference tutorials samples:

https://software.intel.com/en-us/articles/OpenVINO-IE-Samples#interactive-face-detection

We will focus on the "Interactive face detection" sample, and we will work on and extend this tutorial as a demo app aimed to the automotive industry.

== Introduction

This project consists on showcasing the advantages of the Intel's OpenVINO toolkit. We will develop a __Driver Behaviour__ case scenario, where we will detect drowsiness based on blinking and yawning and gaze direction. For that, we will use the OpenVINO toolkit and OpenCV, all written in `{cpp}`.

As mentioned previously, we will take the https://software.intel.com/en-us/articles/OpenVINO-IE-Samples#interactive-face-detection[Interactive face detection sample] as a starting point, as it provides us with the options to run and stack different models synchronously or asynchronously. We will develop the following features based on computer vision:

.  Sleep/Drowsiness Detection:
.. Counting frecuency of blinking.
.. Yawn detection.
. Gaze detection.

We could have other information to build a robust system:

. Heart rate.
. Velocity.
. Acceleration. 

== Bussines Logic

Using OpenVino's model detection we can easily detect faces with great accuracy. We are currently using for testing 2 different face detection models that are included with OpenVino out-of-the-box:

. face-detection-adas-0001
. face-detection-retail-0004

=== Blink/Yawn detection

Using the image detected inside the face ROI (region of interest), we feed a facial landmarks detector to identify points of iterest. Using 6 points for each eye and 6 points for the mouth it is possible to calculate 'Eye Aspect Ratio (EAR)' that gives 2 values for eye/mouth open or closed (based on http://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf[this paper]).

image::https://github.com/incluit/OpenVino-Driver-Behaviour/blob/master/img/blink_detection_6_landmarks.jpg[EAR]

At the moment of writing this guide, the facial landmarks detection model included with OpenVino (facial-landmarks-35-adas-0001) has not enough points to run this calculations. We are using dlib's facial landmarks detector instead.

Once we have a positive detection for blink/yawn, we count frames of those events and trigger an alarm when they hit a threshold.

=== 'Eye out of road' detection

Using the face's ROI, we feed a head-pose detector model provided by OpenVino (head-pose-estimation-adas-0001).
Analizing the output of that model we can easily detect when the face is not centered or not looking to the front.
 
== Prerequisites

To run the application in this tutorial, the OpenVINO™ toolkit and its dependencies must already be installed and verified using the included demos. Installation instructions may be found at: https://software.intel.com/en-us/articles/OpenVINO-Install-Linux

If to be used, any optional hardware must also be installed and verified including:

* USB camera - Standard USB Video Class (UVC) camera.

* Intel® Core™ CPU with integrated graphics.

* VPU - USB Intel® Movidius™ Neural Compute Stick and what is being referred to as "Myriad"

A summary of what is needed:

=== Hardware

* Target and development platforms meeting the requirements described in the "System Requirements" section of the OpenVINO™ toolkit documentation which may be found at: https://software.intel.com/openvino-toolkit[https://software.intel.com/en-us/openvino-toolkit]

**Note**: While writing this tutorial, an Intel® i7-8550U with Intel® HD graphics 520 GPU was used as both the development and target platform.

* Optional:

** Intel® Movidius™ Neural Compute Stick

** USB UVC camera

** Intel® Core™ CPU with integrated graphics.

=== Software

* OpenVINO™ toolkit supported Linux operating system. This tutorial was run on 64-bit Ubuntu 16.04.1 LTS updated to kernel 4.15.0-43 following the OpenVINO™ toolkit installation instructions.

* The latest OpenVINO™ toolkit installed and verified. This tutorial was written using version 2018 R4.0. (Support for R5 has recently been added)

* Git(git) for downloading from the GitHub repository.

* BOOST library. To install on Ubuntu, run:

[source,bash]
----
apt-get install libboost-dev
----

=== Checks

By now you should have completed the Linux installation guide for the OpenVINO™ toolkit, however before continuing, please ensure:

* That after installing the OpenVINO™ toolkit you have run the supplied demo samples 

* If you have and intend to use a GPU: You have installed and tested the GPU drivers 

* If you have and intend to use a USB camera: You have connected and tested the USB camera 

* If you have and intend to use a Myriad: You have connected and tested the USB Intel® Movidius™ Neural Compute Stick

* That your development platform is connected to a network and has Internet access. To download all the files for this tutorial, you will need to access GitHub on the Internet. 

== Build

**1.** Clone the repository at desired location:

[source,bash]
----
git clone https://github.com/incluit/OpenVino-Driver-Behaviour.git
----

**2.** The first step is to configure the build environment for the OpenCV
toolkit by sourcing the "setupvars.sh" script.

[source,bash]
----
source  /opt/intel/computer_vision_sdk/bin/setupvars.sh
----

**3.** Change to the top git repository:

[source,bash]
----
cd OpenVino-Driver-Behaviour
----

**4.** Create a directory to build the tutorial in and change to it.

[source,bash]
----
mkdir build
cd build
----

**5.** Before running each of the following sections, be sure to source the
helper script. That will make it easier to use environment variables
instead of long names to the models:

[source,bash]
----
source ../scripts/setupenv.sh
----

**6.** Compile:

[source,bash]
----
cmake -DCMAKE_BUILD_TYPE=Release ../
make
----

== Usage

=== Run

==== Face Detection

**1.** First, let us see how face detection works on a single image file using the default
synchronous mode.

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face132 -i ../data/img_1.jpg
----

**2.** For video files:

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face132 -i ../data/video1.mp4
----

**3.** You can also run the command in asynchronous mode using the option
"-async":

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face132 -i ../data/video1.mp4 -async
----

**4.** You can also load the models into the **GPU** or **MYRIAD**:

**Note**: In order to run this section, the **GPU** and/or **MYRIAD** are required to be present and correctly configured.

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face132 -d GPU -i ../data/video1.mp4
----

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face132 -d MYRIAD -i ../data/video1.mp4
----

===== Other models

You can also experiment by using different face detection models, being the ones available up to now:

. face-detection-adas-0001:
** `-m $face1{16,32}`
. face-detection-retail-0004:
** `-m $face2{16,32}`

By default they will be loaded into the CPU, so remember to pass the corresponding argument:

* `-d {CPU,GPU,MYRIAD}`


==== Drowsiness detection

In order to enable drowsiness and yawn detection, we add to the pipeline a face landmarks detection.

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face232 -dlib_lm -i ../data/video2.mp4
----

image::https://github.com/incluit/OpenVino-Driver-Behaviour/blob/master/img/blink.gif[blinking]

image::https://github.com/incluit/OpenVino-Driver-Behaviour/blob/master/img/yawning.gif[yawning]

==== Driver 'eyes on the road' detection

To analize if the driver is paying attention to the road, we enable the head/pose model and work with that information:

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face232 -m_hp $hp32 -i ../data/video3.mp4
----

image::https://github.com/incluit/OpenVino-Driver-Behaviour/blob/master/img/gaze.gif[gaze]

==== Realtime feed

Removing the '-i' flag, if the computer has a video camera enabled, the programs uses its feed to run the face detection models and the following calculations.

[source,bash]
----
./intel64/Release/driver_behaviour_tutorial -m $face232
./intel64/Release/driver_behaviour_tutorial -m $face232 -dlib_lm
./intel64/Release/driver_behaviour_tutorial -m $face232 -d GPU -dlib_lm -async
./intel64/Release/driver_behaviour_tutorial -m $face232 -m_hp $hp32
----

== To Do

=== README

* [x] Short README with usage examples
* [x] Travis + Sonarcloud
* [ ] Include diagrams and images
* [ ] Elaborate on the wiki

=== Development

* [x] Try with different models
* [x] Face detection
* [x] Dlib landmark idetification integration
* [x] Blink/Yawn detection
* [x] Blink/Yawn time
* [x] 'Eye out of road' detection
* [x] Face identification
* [ ] Heart rate + speed/acceleration patterns risk
